{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b11271-975c-4e64-aad2-44d50a6de00d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T17:49:45.356219097Z",
     "start_time": "2023-08-14T17:49:45.183544170Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79343c71-c8b3-4f53-bac0-cfed6f1c30dd",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb85c648-fe74-4cd9-b508-003f4c7aee95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T17:49:45.361605133Z",
     "start_time": "2023-08-14T17:49:45.360740587Z"
    }
   },
   "outputs": [],
   "source": [
    "p_new_node = 0.5\n",
    "community_mat = np.array([[0.9, 0.1], [0.1, 0.9]])\n",
    "N_timesteps = 6\n",
    "N_nodes = 50\n",
    "N_edge_per_time = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc63f036-0d38-4cc1-8a2e-8b324aaade6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9, 0.1],\n",
       "       [0.1, 0.9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcff5225-f4bd-43b8-9826-c404d279d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_mat = np.array([[0.9, 0.1, 0.1, 0.1], [0.1, 0.9, 0.1, 0.1], [0.1, 0.1, 0.9, 0.1], [0.1, 0.1, 0.1, 0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09267f2d-e512-4953-929e-830323278ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(community_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de4d03-3cdf-4c33-97e8-70a8c1264a8b",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d240f29-5c46-462e-9723-af0152c33fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_probs(p):\n",
    "    p = np.asarray(p).astype('float64')\n",
    "    p = p / np.sum(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df10569f-bd7f-4610-99d2-738f19c9aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hypergraph(p_new_node, community_mat, N_timesteps, N_edge_per_time):\n",
    "    G = nx.Graph()\n",
    "    counter = 0\n",
    "    node_to_com = {}\n",
    "    \n",
    "    all_nodes = range(N_nodes)\n",
    "    \n",
    "    for node in all_nodes:\n",
    "        name = ''.join(random.choice([chr(i) for i in range(ord('a'),ord('z'))]) for _ in range(6))\n",
    "        node_to_com[node] = np.random.randint(len(community_mat), size=1)[0]\n",
    "        G.add_node(node, label=\"person\", name=name, comm=int(node_to_com[node]))\n",
    "    \n",
    "    for time in range(1, N_timesteps+1):\n",
    "        for new_edge in range(N_edge_per_time):\n",
    "            node_id = np.random.randint(N_nodes, size=1)[0]\n",
    "            nodes_of_edge = [node_id]\n",
    "            \n",
    "            r = 0\n",
    "            while r < p_new_node:    \n",
    "                node_props = [community_mat[node_to_com[node_id], node_to_com[node]] for node in all_nodes]\n",
    "                new_node = np.random.choice(all_nodes, p=normalize_probs(node_props))\n",
    "                nodes_of_edge.append(new_node)\n",
    "                r = random.random()\n",
    "                \n",
    "            hyperedge = \"h\" + str(counter)\n",
    "            counter += 1\n",
    "            G.add_node(hyperedge, time=time, label=\"document\")\n",
    "            for node in nodes_of_edge:\n",
    "                G.add_edge(hyperedge, node, label=\"edge\")\n",
    "                \n",
    "    return G  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d709dcc9-967e-4d0b-8893-01c9eeaf610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "G = generate_hypergraph(p_new_node, community_mat, N_timesteps, N_edge_per_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4e719-2d11-4967-b9f0-ebfc3d4201a7",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1cce7b83-2f65-45fe-b957-cea935e32eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_json = nx.node_link_data(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a3bade70-b475-42cd-9140-acf269ab17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_json[\"metadata\"] = {\n",
    "            \"datasetName\": \"test\",\n",
    "            \"edgeType\": \"label\",\n",
    "            \"entityType\": \"label\",\n",
    "            \"name\": \"name\",\n",
    "            \"source_entity_type\": \"document\",\n",
    "            \"target_entity_type\": \"person\",\n",
    "            \"time_key\": \"time\",\n",
    "            # \"entityTypes\": [entity_type for entity_type in self.node_labels],\n",
    "            # \"attributes\": [{\"name\": property.name, \"type\": property.type} for property in self.properties]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e70b3aec-e121-4847-9d59-3bf63b8c3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"test_gen.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "097a69b1-3b48-44cb-815e-b94463afdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fp, \"w+\") as path:\n",
    "    json.dump(graph_json, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88071c-cf9c-43e3-8c14-0e35e70d4d3f",
   "metadata": {},
   "source": [
    "## Agent based Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8f69a2e-14f6-4156-8f85-b7a532d655f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample list of animal names\n",
    "animal_names = {\n",
    "    \"cat\", \"dog\", \"elephant\", \"giraffe\", \"lion\", \"tiger\", \"panda\", \"koala\", \"kangaroo\",\n",
    "    \"zebra\", \"hippo\", \"bear\", \"wolf\", \"fox\", \"rhino\", \"cheetah\", \"penguin\", \"dolphin\",\n",
    "    \"whale\", \"shark\", \"eagle\", \"hawk\", \"falcon\", \"owl\", \"sparrow\", \"hummingbird\", \"parrot\",\n",
    "    \"peacock\", \"duck\", \"swan\", \"goose\", \"rabbit\", \"squirrel\", \"deer\", \"moose\", \"gazelle\",\n",
    "    \"monkey\", \"gorilla\", \"chimpanzee\", \"orangutan\", \"lemur\", \"hyena\", \"leopard\", \"panther\",\n",
    "    \"crocodile\", \"alligator\", \"snake\", \"turtle\", \"frog\", \"lizard\", \"octopus\", \"squid\", \"crab\",\n",
    "    \"lobster\", \"shrimp\", \"starfish\", \"jellyfish\", \"seahorse\", \"snail\", \"butterfly\", \"bee\",\n",
    "    \"ant\", \"beetle\", \"ladybug\", \"spider\", \"scorpion\", \"tarantula\", \"hedgehog\", \"armadillo\",\n",
    "    \"platypus\", \"kookaburra\", \"emu\", \"wombat\", \"tasmanian devil\", \"kiwi\", \"ostrich\", \"rhinoceros beetle\",\n",
    "    \"buffalo\", \"moose\", \"raccoon\", \"skunk\", \"porcupine\", \"hedgehog\", \"polar bear\", \"walrus\",\n",
    "    \"seal\", \"otters\", \"sloth\", \"anteater\", \"aardvark\", \"reindeer\", \"antelope\", \"caribou\",\n",
    "    \"yak\", \"gnu\", \"hippopotamus\", \"hyena\", \"jackal\", \"elephant seal\", \"meerkat\", \"armadillo\",\n",
    "    \"black bear\", \"chinchilla\", \"fennec fox\", \"lynx\", \"jaguar\", \"quokka\", \"tarsier\", \"anteater\",\n",
    "    \"capybara\", \"okapi\", \"lemur\", \"leopard\", \"manatee\", \"numbat\", \"pangolin\", \"red panda\",\n",
    "    \"serval\", \"tapir\", \"bongo\", \"bongo\", \"fossa\", \"gibbon\", \"saki monkey\", \"tit\", \"toucan\",\n",
    "    \"star-nosed mole\", \"springhare\", \"armadillo girdled lizard\", \"numbat\", \"sugar glider\", \"wallaroo\",\n",
    "    \"red-handed tamarin\", \"green basilisk\", \"glass frog\", \"flying dragon\", \"pufferfish\", \"blowfish\",\n",
    "    \"lionfish\", \"scorpionfish\", \"mandarin fish\", \"blue tang\", \"parrotfish\", \"yellow tang\",\n",
    "    \"flounder\", \"swordfish\", \"goblin shark\", \"hammerhead shark\", \"bull shark\", \"mako shark\",\n",
    "    \"giant manta ray\", \"stingray\", \"sea turtle\", \"leatherback turtle\", \"box turtle\",\n",
    "    \"green sea turtle\", \"giant panda\", \"red fox\", \"sea otter\", \"jaguar\", \"siberian tiger\",\n",
    "    \"bald eagle\", \"harpy eagle\", \"humpback whale\", \"blue whale\", \"orca\", \"bottlenose dolphin\",\n",
    "    \"gray wolf\", \"golden eagle\", \"african elephant\", \"indian elephant\", \"saltwater crocodile\",\n",
    "    \"american alligator\", \"black rhinoceros\", \"white rhinoceros\", \"black mamba\", \"king cobra\",\n",
    "    \"reticulated python\", \"green anaconda\", \"nile crocodile\", \"poison dart frog\",\n",
    "    \"giant african millipede\", \"giant centipede\", \"tarantula\", \"giant desert hairy scorpion\",\n",
    "    \"black widow spider\", \"african lion\", \"cheetah\", \"leopard\", \"giraffe\", \"african elephant\",\n",
    "    \"grizzly bear\", \"polar bear\", \"red kangaroo\", \"blue whale\", \"bengal tiger\", \"siberian tiger\",\n",
    "    \"american bison\", \"american flamingo\", \"african penguin\", \"african grey parrot\",\n",
    "    \"green tree python\", \"chimpanzee\", \"koala\", \"arctic fox\", \"snow leopard\", \"red panda\",\n",
    "    \"sloth\", \"raccoon\", \"meerkat\", \"black-footed ferret\", \"beaver\", \"giant panda\", \"honey badger\",\n",
    "    \"prairie dog\", \"sea lion\", \"walrus\", \"gray whale\", \"elephant seal\", \"macaw\", \"scarlet macaw\",\n",
    "    \"cockatoo\", \"hummingbird\", \"woodpecker\", \"kingfisher\", \"puffin\", \"hornbill\", \"horned owl\",\n",
    "    \"barn owl\", \"peregrine falcon\", \"osprey\", \"buzzard\", \"red-tailed hawk\", \"harpy eagle\",\n",
    "    \"bald eagle\", \"bearded vulture\", \"black vulture\", \"turkey vulture\", \"pheasant\", \"quail\",\n",
    "    \"partridge\", \"guinea fowl\", \"dove\", \"pigeon\", \"stork\", \"crane\", \"flamingo\", \"pelican\",\n",
    "    \"swan\", \"goose\", \"duck\", \"heron\", \"ibis\", \"egret\", \"spoonbill\", \"albatross\", \"seagull\",\n",
    "    \"tern\", \"frigatebird\", \"penguin\", \"ostrich\", \"emu\", \"kiwi\", \"cassowary\", \"rhea\", \"toad\",\n",
    "    \"frog\", \"salamander\", \"newt\", \"caecilian\", \"crocodile\", \"alligator\", \"gavial\", \"iguana\",\n",
    "    \"chameleon\", \"komodo dragon\", \"gecko\", \"monitor lizard\", \"skink\", \"cobra\", \"viper\",\n",
    "    \"rattlesnake\", \"black mamba\", \"king cobra\", \"anaconda\", \"python\", \"boa constrictor\",\n",
    "    \"sea snake\", \"grass snake\", \"water snake\", \"garter snake\", \"hognose snake\", \"milk snake\"}\n",
    "\n",
    "def name_generator():\n",
    "    random_animal = random.sample(animal_names, 1)[0]\n",
    "    # animal_names.remove(random_animal)\n",
    "    return random_animal\n",
    "    # return ''.join(random.choice([chr(i) for i in range(ord('a'),ord('z'))]) for _ in range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "652bc061-c054-4b27-9671-e662dd92ce99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284591/2158273777.py:47: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random_animal = random.sample(animal_names, 1)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pigeon'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "113b23e4-923b-47e8-a481-83b9ecba6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, id, name, com):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.com = com\n",
    "        self.dead = False\n",
    "        \n",
    "    def timestep_run(self, N_coms, p_dying = 0.01, p_switch_com=0.08):\n",
    "        self.N_coms = N_coms\n",
    "        r = random.random()\n",
    "        r2 = random.random()\n",
    "        if r < p_dying:\n",
    "            self.dead = True\n",
    "        if r2 < p_switch_com:\n",
    "            self.switch_comm()\n",
    "            \n",
    "    def switch_comm(self):\n",
    "        new_com = -1\n",
    "        while self.com != new_com:\n",
    "            new_com = random.randint(0, self.N_coms - 1)\n",
    "        self.com = int(new_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "206502e4-9e48-4f8c-9ecd-3dcdb9cf6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_counter = 0\n",
    "\n",
    "class Community:\n",
    "    def __init__(self):\n",
    "        self.id = com_counter\n",
    "        com_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bff15401-337f-433f-91e9-3cc3b6e253e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full([3, 3], 3.14)\n",
    "a.flat[0::4] = -2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "481037c3-e146-4904-982c-74eacc09e93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.  ,  3.14,  3.14],\n",
       "       [ 3.14, -2.  ,  3.14],\n",
       "       [ 3.14,  3.14, -2.  ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75069483-7205-4ff5-b025-7df9d8bb92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.N_timesteps = 8\n",
    "        self.N_nodes = 60\n",
    "        # self.N_edge_per_time = int(self.N_nodes / 6)\n",
    "        self.N_edge_per_time = 25\n",
    "        \n",
    "        self.p_new_node = 0.05\n",
    "        self.p_add_he_node = 0.3\n",
    "        \n",
    "        self.p_com_dying = 0.1\n",
    "        self.p_com_appear = 0.2\n",
    "        self.p_com_merge = 0.15\n",
    "        \n",
    "    \n",
    "        self.counter = 0\n",
    "        self.N_coms = 5\n",
    "        \n",
    "        # self.community_mat = np.array([[1.5, 0.1, 0.1], [0.1, 1.5, 0.1], [0.1, 1.5, 2]])\n",
    "        # self.community_mat = np.array([[1.5, 0.1], [0.1, 1.5]])\n",
    "        # self.community_mat = np.array([[2, 0.1, 0.1, 0.1], [0.1, 2, 0.1, 0.1], [0.1, 0.1, 2, 0.1], [0.1, 0.1, 0.1, 2]])\n",
    "        # self.community_mat = np.full([self.N_coms, self.N_coms], 1)\n",
    "        # self.community_mat.flat[0::(self.N_coms + 1)] = 40\n",
    "        \n",
    "        self.community_mat = np.full([self.N_coms, self.N_coms], 0.05)\n",
    "        self.community_mat.flat[0::(self.N_coms + 1)] = 0.5\n",
    "        \n",
    "        print(self.community_mat)\n",
    "        \n",
    "        self.coms_dead = set()\n",
    "    \n",
    "        \n",
    "    def nodes_of_community(self, com_id):\n",
    "        return [node for node in self.all_nodes if node.com == com_id]\n",
    "        \n",
    "    def start(self):\n",
    "        self.G = nx.Graph()\n",
    "        # self.node_to_com = {}\n",
    "        self.all_nodes = []\n",
    "        for idnode in range(self.N_nodes):\n",
    "            name = self.new_name()\n",
    "            com = int(np.random.randint(len(self.community_mat), size=1)[0])\n",
    "            node = Node(idnode, name, com)\n",
    "            self.all_nodes.append(node)\n",
    "            \n",
    "#             TODO : com attribute\n",
    "            self.G.add_node(node.id, label=\"person\", name=name, comm=node.com)\n",
    "        \n",
    "    def living_nodes(self):\n",
    "        return [node for node in self.all_nodes if not node.dead]\n",
    "    \n",
    "    def living_nodes_ids(self):\n",
    "        return [node.id for node in self.living_nodes()]\n",
    "    \n",
    "    def timestep_run(self):\n",
    "        for node in self.living_nodes():\n",
    "            node.timestep_run(len(self.community_mat))\n",
    "            \n",
    "        for com_id, community in enumerate(self.community_mat):\n",
    "            r = random.random()\n",
    "            if com_id not in self.coms_dead and r < self.p_com_dying:\n",
    "                print(\"COM DEAD\")\n",
    "                self.coms_dead.add(com_id)\n",
    "                nodes = self.nodes_of_community(com_id)\n",
    "                for node in nodes:\n",
    "                    node.dead = True\n",
    "                    \n",
    "        r = random.random()\n",
    "        if r < self.p_com_appear:\n",
    "            print(\"NEW COM\")\n",
    "            self.N_coms += 1\n",
    "            self.community_mat = np.full([self.N_coms, self.N_coms], 1)\n",
    "            self.community_mat.flat[0::(self.N_coms + 1)] = 40\n",
    "            \n",
    "            n_new_nodes = int(len(self.living_nodes()) / self.N_living_coms())\n",
    "            for i in range(n_new_nodes):\n",
    "                self.add_node(self.N_coms - 1)\n",
    "                \n",
    "                \n",
    "    def add_node(self, com):\n",
    "        node_id = len(self.all_nodes)\n",
    "        name = self.new_name()\n",
    "\n",
    "        node = Node(node_id, name, com)\n",
    "        self.all_nodes.append(node)\n",
    "        self.G.add_node(node_id, label=\"person\", name=name, comm=com)\n",
    "        \n",
    "    def new_name(self):\n",
    "        name = name_generator()\n",
    "        if name in dict(self.G.nodes(data=\"name\")).values():\n",
    "            name = name + \"'\"\n",
    "        return name\n",
    "            \n",
    "    def N_living_coms(self):\n",
    "        return self.N_coms - len(self.coms_dead)\n",
    "        \n",
    "    def run(self):\n",
    "        self.start()\n",
    "        for time in range(1, self.N_timesteps+1):\n",
    "            self.generate_hyperedges(time)\n",
    "            self.timestep_run()\n",
    "            \n",
    "    def generate_hyperedges(self, time):\n",
    "        self.generate_hyperedges_static(time)\n",
    "        \n",
    "    def generate_hyperedges_blockmodel(self, time):\n",
    "        for i, node in enumerate(self.living_nodes()):\n",
    "            for node2 in self.living_nodes()[(i+1):]:\n",
    "                if node != node2:\n",
    "                    r = random.random()\n",
    "                    if r < self.community_mat[node.com, node2.com]:\n",
    "                        nodes_of_edge = [node.id, node2.id]\n",
    "                        r2 = random.random()\n",
    "                        while r2 < self.p_add_he_node:    \n",
    "                            new_node = self.select_node(node, True)\n",
    "                            nodes_of_edge.append(new_node.id)\n",
    "                            r2 = random.random()\n",
    "                        \n",
    "                        hyperedge = \"h\" + str(self.counter)\n",
    "                        self.counter += 1\n",
    "                        self.G.add_node(hyperedge, ts=time, label=\"document\")\n",
    "                        for node in nodes_of_edge:\n",
    "                            self.G.add_edge(hyperedge, node, label=\"edge\")\n",
    "        \n",
    "    def generate_hyperedges_static(self, time):\n",
    "        for new_edge in range(self.N_edge_per_time):\n",
    "            first_new_node = self.select_node(False)\n",
    "            nodes_of_edge = [first_new_node.id]\n",
    "\n",
    "            r = 0\n",
    "            while r < self.p_add_he_node:    \n",
    "                new_node = self.select_node(first_new_node, True)\n",
    "                nodes_of_edge.append(new_node.id)\n",
    "                r = random.random()\n",
    "\n",
    "            hyperedge = \"h\" + str(self.counter)\n",
    "            self.counter += 1\n",
    "\n",
    "            # self.G.add_node(hyperedge, time=time, label=\"document\")\n",
    "#                 Paohvis format\n",
    "            self.G.add_node(hyperedge, ts=time, label=\"document\")\n",
    "\n",
    "            for node in nodes_of_edge:\n",
    "                self.G.add_edge(hyperedge, node, label=\"edge\")\n",
    "                    \n",
    "    def select_node(self, neighbor=None, weights=False):\n",
    "        r0 = random.random()\n",
    "        if r0 < self.p_new_node:\n",
    "            # New Node\n",
    "            node_id = len(self.all_nodes)\n",
    "            name = self.new_name()\n",
    "            \n",
    "            # new_com = random.randint(0, len(self.community_mat) - 1)\n",
    "            new_com = random.choice(list(set(range(self.N_coms)) - self.coms_dead))\n",
    "            \n",
    "            node = Node(node_id, name, new_com)\n",
    "            self.all_nodes.append(node)\n",
    "            self.G.add_node(node_id, label=\"person\", name=name, comm=new_com)\n",
    "        else:\n",
    "            if weights:\n",
    "#                 TODO: Normalize given the number of nodes\n",
    "                node_props = [self.community_mat[neighbor.com, node.com] for node in self.living_nodes()]\n",
    "                # print(normalize_probs(node_props))\n",
    "                node = np.random.choice(self.living_nodes(), p=normalize_probs(node_props))\n",
    "            else:\n",
    "                node = np.random.choice(self.living_nodes(), size=1)[0]\n",
    "        return node\n",
    "    \n",
    "    def to_json(self):\n",
    "        graph_json = nx.node_link_data(self.G)        \n",
    "        # graph_json[\"metadata\"] = {\n",
    "        #     \"datasetName\": \"test\",\n",
    "        #     \"edgeType\": \"label\",\n",
    "        #     \"entityType\": \"label\",\n",
    "        #     \"name\": \"name\",\n",
    "        #     \"source_entity_type\": \"document\",\n",
    "        #     \"target_entity_type\": \"person\",\n",
    "        #     \"time_key\": \"time\",\n",
    "        #     # \"entityTypes\": [entity_type for entity_type in self.node_labels],\n",
    "        #     # \"attributes\": [{\"name\": property.name, \"type\": property.type} for property in self.properties]\n",
    "        # }\n",
    "        \n",
    "#         For Paohvis\n",
    "        graph_json[\"metadata\"] = {\n",
    "            \"datasetName\": \"test\",\n",
    "            \"edgeType\": \"label\",\n",
    "            \"entityType\": \"label\",\n",
    "            \"name\": \"name\",\n",
    "            \"source_entity_type\": \"document\",\n",
    "            \"target_entity_type\": \"person\",\n",
    "            \"time_key\": \"time\",\n",
    "            \"format\": \"2.1.0\",\n",
    "            \"entity_type\": \"label\",\n",
    "        }\n",
    "        \n",
    "        return graph_json\n",
    "        \n",
    "    def export(self):\n",
    "        fp = f\"{self.N_timesteps}times_{self.N_coms}coms.json\"\n",
    "        with open(fp, \"w+\") as path:\n",
    "            json.dump(self.to_json(), path)\n",
    "            \n",
    "        with open(\"output.json\", \"w+\") as path:\n",
    "            json.dump(self.to_json(), path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73fc2a6b-0d82-4db0-ad50-a82841a2785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5  0.05 0.05 0.05 0.05]\n",
      " [0.05 0.5  0.05 0.05 0.05]\n",
      " [0.05 0.05 0.5  0.05 0.05]\n",
      " [0.05 0.05 0.05 0.5  0.05]\n",
      " [0.05 0.05 0.05 0.05 0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "g = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "471a7682-c6ae-4690-bf97-aa6d544bb6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW COM\n",
      "COM DEAD\n",
      "COM DEAD\n",
      "COM DEAD\n",
      "NEW COM\n",
      "COM DEAD\n",
      "COM DEAD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284591/2158273777.py:47: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random_animal = random.sample(animal_names, 1)[0]\n"
     ]
    }
   ],
   "source": [
    "g.run()\n",
    "g.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6191e6-834b-48c3-abb5-ad6a006d2241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
